{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Timeseries Properties, Autoregressive and Moving Average Models\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "\n",
    "### Core\n",
    "\n",
    "- Understand the different components of an ARIMA model\n",
    "- Fit an ARIMA model with statsmodels\n",
    "- Forecast with the fitted model\n",
    "- Evaluate the model\n",
    "\n",
    "### Target\n",
    "\n",
    "- Know about some common patterns in (partial) autocorrelations and their relations to ARIMA models\n",
    "- Investigate the residuals\n",
    "- Know about model limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-Objectives\" data-toc-modified-id=\"Learning-Objectives-1\">Learning Objectives</a></span><ul class=\"toc-item\"><li><span><a href=\"#Core\" data-toc-modified-id=\"Core-1.1\">Core</a></span></li><li><span><a href=\"#Target\" data-toc-modified-id=\"Target-1.2\">Target</a></span></li></ul></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-2\">Introduction</a></span></li><li><span><a href=\"#Load-the-unemployment-data\" data-toc-modified-id=\"Load-the-unemployment-data-3\">Load the unemployment data</a></span></li><li><span><a href=\"#Create-a-datetime-index\" data-toc-modified-id=\"Create-a-datetime-index-4\">Create a datetime index</a></span></li><li><span><a href=\"#Visually-examine-the-unemployment-rate\" data-toc-modified-id=\"Visually-examine-the-unemployment-rate-5\">Visually examine the unemployment rate</a></span></li><li><span><a href=\"#Time-series-models\" data-toc-modified-id=\"Time-series-models-6\">Time series models</a></span></li><li><span><a href=\"#ARMA-and-ARIMA-models\" data-toc-modified-id=\"ARMA-and-ARIMA-models-7\">ARMA and ARIMA models</a></span></li><li><span><a href=\"#Fitting-ARIMA-models\" data-toc-modified-id=\"Fitting-ARIMA-models-8\">Fitting ARIMA models</a></span></li><li><span><a href=\"#How-to-choose-the-right-p-and-q-parameters\" data-toc-modified-id=\"How-to-choose-the-right-p-and-q-parameters-9\">How to choose the right <code>p</code> and <code>q</code> parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-tuning\" data-toc-modified-id=\"Model-tuning-9.1\">Model tuning</a></span></li><li><span><a href=\"#Automatic-selection-of-ARMA-model-based-on-AIC-or-BIC\" data-toc-modified-id=\"Automatic-selection-of-ARMA-model-based-on-AIC-or-BIC-9.2\">Automatic selection of ARMA model based on AIC or BIC</a></span></li><li><span><a href=\"#Let's-fit-our-best-model-according-to-BIC,-ARMA(2,3)\" data-toc-modified-id=\"Let's-fit-our-best-model-according-to-BIC,-ARMA(2,3)-9.3\">Let's fit our best model according to BIC, ARMA(2,3)</a></span></li><li><span><a href=\"#Forecast-for-this-model\" data-toc-modified-id=\"Forecast-for-this-model-9.4\">Forecast for this model</a></span></li><li><span><a href=\"#Scores\" data-toc-modified-id=\"Scores-9.5\">Scores</a></span></li><li><span><a href=\"#Residuals\" data-toc-modified-id=\"Residuals-9.6\">Residuals</a></span></li></ul></li><li><span><a href=\"#Summary-of-time-series-modeling\" data-toc-modified-id=\"Summary-of-time-series-modeling-10\">Summary of time series modeling</a></span></li><li><span><a href=\"#Model-Limitations\" data-toc-modified-id=\"Model-Limitations-11\">Model Limitations</a></span></li><li><span><a href=\"#Additional-Resources\" data-toc-modified-id=\"Additional-Resources-12\">Additional Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lesson we will meet one of the main classes of time series models, **ARIMA (Autoregressive Integrated Moving Average Models)**. We will use statsmodels to fit ARIMA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set(font_scale=1.5)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will filter out a lot of future warnings from statsmodels\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr_plots(y, lags=None):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n",
    "    plot_acf(y, lags=lags, ax=ax[0])\n",
    "    plot_pacf(y, lags=lags, ax=ax[1])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the unemployment data\n",
    "\n",
    "\n",
    "This is historical monthly unemployment data in the US that we have previously cleaned and explored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    '../datasets/unemployment_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a datetime index\n",
    "\n",
    "\n",
    "We have to make sure the index is the `datetime` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date']).dt.to_period('M')\n",
    "data.set_index('date', inplace=True, drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visually examine the unemployment rate\n",
    "\n",
    "Make a plot of the unemployment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['unemployment_rate'].plot(lw=4, figsize=(12, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's keep unemployment_rate as a variable for later\n",
    "urate = data.unemployment_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series models\n",
    "\n",
    "\n",
    "What we would like to do in time series modeling is to predict future values in the time series from the preceding ones, e.g.\n",
    "\n",
    "- the price of an asset tomorrow given the price today\n",
    "- tomorrow's weather given today's weather and last week's and last year's at the same date\n",
    "\n",
    "We will have to formulate something like\n",
    "\n",
    "$$\n",
    "y_t = f(y_{t-1},y_{t-2},\\ldots,y_{1},y_{0}) + \\epsilon_t\n",
    "$$\n",
    "\n",
    "The task is to find the appropriate function defining our model. As usual, we will have some irreducible error limiting the quality of our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMA and ARIMA models\n",
    "\n",
    "**ARMA** models are essentially regression models. To predict the value $y_t$ of the time series at time $t$, we use: \n",
    "- the preceding observations $y_{t-1}, y_{t-2}, \\ldots, y_{t-p}$ up to $p$ previous time steps. This is called the **Autoregressive (AR)** component of the model. \n",
    "- the preceding noise terms $\\epsilon_{t-1}, \\epsilon_{t-2}, \\ldots, \\epsilon_{t-q}$ up to q previous time steps. This is called the **Moving Average (MA)** component of the model. \n",
    "\n",
    "In this way we base our predictions on previous observations, and we also prescribe a way to predict how being wrong about the last predictions should influence our future predictions.\n",
    "\n",
    "In total, our model will have $p+q$ parameters and can be formulated like this:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "y_t &=& \\phi_0 + \\phi_1  y_{t-1}\\ +\\ ...\\ +\\ \\phi_p  y_{t-p}\\ + \\theta_{1} \\epsilon_{t-1} + ... +\\theta_{q} \\epsilon_{t-n} +\\ \\epsilon_t \\\\\n",
    "y_t &=& \\phi_0+\\sum_{j=1}^p \\phi_j y_{t-j} + \\sum_{i=1}^q \\theta_i \\epsilon_{t-i} + \\epsilon_t\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\phi_0=\\left(1-\\sum_{j=1}^p \\phi_j\\right)\\mu$$\n",
    "\n",
    "Here $\\mu$ is the mean of the time series, and $\\epsilon_t$ are uncorrelated noise terms stemming from the same normal distribution with mean zero and the same standard deviation.\n",
    "\n",
    "For the ARMA model to work properly, the time series is required to be stationary. If initially it is not stationary, it may be made stationary (to sufficient degree) by suitable transformations and differencing.\n",
    "\n",
    "The Auto Regressive Integrated Moving Average Model (**ARIMA**)\n",
    "is basically the same as an \n",
    "`ARMA(p, q)` model, but we additionally indicate how many differencing steps we carried out, i.e. we just plug in our initial unemployment rate time series, and then indicate that we want to have it differenced $d$ times ($d=1$ in our case) before fitting an `ARMA(p,q)` model to it.\n",
    "\n",
    "We denote this as an `ARIMA(p,d,q)` model.\n",
    "\n",
    "Whereas fitting the AR part is straightforward, fitting the MA part is a bit more tricky because the error terms are unobserved. There are a variety of different ways you can estimate the parameters, some of which are covered in this [paper.](https://www.it.uu.se/research/publications/reports/2006-022/2006-022-nc.pdf)\n",
    "\n",
    "In the simpler fitting procedures, a model is iteratively fit, errors are computed, then refit, over and over again until the parameters of the errors converge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def autocorr_plots(y, lags=None):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n",
    "    plot_acf(y, lags=lags, ax=ax[0])\n",
    "    plot_pacf(y, lags=lags, ax=ax[1])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = autocorr_plots(urate,lags=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradually declining ACF indicates that the time series is non stationary, because the autocorrelation changes over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test for Stationarity\n",
    "\n",
    "A statistical test for stationarity is the Augmented Dickey-Fuller test:\n",
    "- H0: There is a unit root in a time series sample (indicating it is non-stationary)\n",
    "- H1: There is no unit root (so it is stationary)\n",
    "\n",
    "if the p-value is less than the significance level then we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_test = adfuller(urate)\n",
    "print(f'p-value: {adf_test[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our p-value is not less than 0.05, we do not reject the null hypothesis that the time series is not stationary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting ARIMA models\n",
    "\n",
    "\n",
    "Fitting ARIMA models is very simple. Just pass the argument `order=(p,d,q)` to indicate the order of the ARIMA model. \n",
    "\n",
    "See the [statsmodels documentation](https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html).\n",
    "\n",
    "For example, suppose we decided on `p=2`, `d=0`, `q=1`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the training and test sets:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train based on data up to one year prior\n",
    "n = len(urate)-12\n",
    "X_train= urate[:n]\n",
    "X_test= urate[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "model_test_201=ARIMA(X_train, order=(2,0,1)).fit()\n",
    "print(model_test_201.summary())\n",
    "print(model_test_201.model.order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the coefficients for the constant term ($\\phi_0$) + ($\\epsilon_t$) ,  2 AR coefficients ($\\phi_1$) and ($\\phi_2$), and 1 MA coefficient ($\\theta_1$) for the ARIMA equation:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "y_t &=& \\phi_0 + \\phi_1  y_{t-1}\\ +\\ ...\\ +\\ \\phi_p  y_{t-p}\\ + \\theta_{1} \\epsilon_{t-1} + ... +\\theta_{q} \\epsilon_{t-n} +\\ \\epsilon_t \\\\\n",
    "y_t &=& \\phi_0+\\sum_{j=1}^p \\phi_j y_{t-j} + \\sum_{i=1}^q \\theta_i \\epsilon_{t-i} + \\epsilon_t\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "And this is the equation that will be used to forecast the `y` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast 12 months\n",
    "forecast_test_201 = model_test_201.forecast(len(X_test))\n",
    "\n",
    "# Store the forecast values back in the dataframe, keeping those before the y_test as NaN\n",
    "data['forecast_test_201'] = [None]*len(X_train) + list(forecast_test_201)\n",
    "\n",
    "data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['2022-01':].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning\n",
    "\n",
    "\n",
    "Now let's try to identify suitable values for the ARIMA model:\n",
    "- AR(p) \n",
    "- MA(q)\n",
    "- differencing (d)\n",
    "\n",
    "- p indicates how many prior time periods are taken into consideration for explained autocorrelation. Increasing p would increase the dependency on previous values further (longer lag).\n",
    "- q indicates how many prior time periods we are considering for observing sudden trend changes.\n",
    "- d indicates what difference we are anticipating to predict. We pick d in such a way that we produce a stationary time series (if we can)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing `d` parameter\n",
    "\n",
    "The `d` parameter specifies the amount of differencing required to make the series stationary. We can inspect the differenced values for stationarity using the ACF, PACF plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the differenced series, dropping the first row which will be NaN\n",
    "udiff = urate.diff()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udiff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ACF and PACF\n",
    "autocorr_plots(udiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differenced values appear to be stationary, with no significant correlation between each time step and the next. Let's check by performing the ADF test on the differenced series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test = adfuller(udiff)\n",
    "print(f'p-value: {adf_test[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is very low, so we reject the null hypothesis that there is a unit root, and we can use the assumption that the differenced series is stationary.\n",
    "\n",
    "So let's go ahead and use `d=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose the right `p` and `q` parameters\n",
    "---\n",
    "<a id=\"how-to-choose-the-right-p-and-q-parameters\"></a>\n",
    "\n",
    "In general it is never a bad idea to choose your parameters based on hold-out testing. That is to say, checking the performance of your model on future time points based on different choices of `p` and `q` for an ARIMA model.\n",
    "\n",
    "However, you can get a sense for what parameters will work best based on the autocorrelation and partial autocorrelation plots.\n",
    "\n",
    "[This site](https://people.duke.edu/~rnau/411arim3.htm) has a very detailed overview of how to use the acf and pacf to determine your parameters.\n",
    "\n",
    "Below are some basic guidelines which are applicable once your time series is stationary, i.e. you might have to carry out transformations and/or differencing steps before.\n",
    "\n",
    "After having obtained the stationary time series, inspect the autocorrelation and partial autocorrelation plots.\n",
    "\n",
    "- Check the autocorrelations.\n",
    "- If all autocorrelations with a lag larger than q vanish, choose MA(q).\n",
    "- If there are autocorrelations at all lags (even if maybe very small), check for the partial autocorrelations.\n",
    "- If the partial autocorrelations for lags larger than p vanish, choose AR(p).\n",
    "- If both the ACF and PACF show a gradual decay, an ARMA model is likely appropriate as opposed to the AR or MA alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = autocorr_plots(urate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot above we see that there are no significant lags in the PACF after p=1. So we can use `p=1`.\n",
    "\n",
    "The ACF plot shows autocorrelation for up to lag 15, showing that the values up to 15 lags could be relevant to the current time value. Let's try `q=15`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_1_15=ARIMA(X_train, order=(1,1,15)).fit()\n",
    "print(model_1_1_15.summary())\n",
    "print(model_1_1_15.model.order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_1_1_15 = model_1_1_15.forecast(len(X_test))\n",
    "\n",
    "data['forecast_1_1_15'] = [None]*len(X_train) + list(forecast_1_1_15)\n",
    "\n",
    "data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['2022-01':].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals\n",
    "\n",
    "As in linear regression, we can judge the quality of our model by looking at our residuals. We would like that\n",
    "\n",
    "- there are no trends in the size of the residuals\n",
    " - plot the values of the residuals \n",
    "- the residuals are uncorrelated\n",
    " - plot the autocorrelations of the residuals (correlogram)\n",
    "- the residuals are normally distributed \n",
    " - compare to the standard normal distribution through quantile-quantile plot and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def residual_plot(res):\n",
    "    resid_standard = (res - res.mean()) / res.std()\n",
    "\n",
    "    figure, ax = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "\n",
    "    ax[0, 0].plot(res)\n",
    "    ax[0, 0].axhline(res.mean(), color='grey')\n",
    "    ax[0, 0].set_title('Residuals')\n",
    "\n",
    "    plot_acf(resid_standard, title='Correlogram', ax=ax[0, 1])\n",
    "\n",
    "    sm.graphics.qqplot(res, line='45', fit=True, ax=ax[1, 0])\n",
    "    ax[1, 0].set_title('Normal Q-Q')\n",
    "\n",
    "    x = np.linspace(res.min(), res.max(), 1000)\n",
    "    norm = stats.norm(loc=0, scale=res.std())\n",
    "    sns.distplot(res, ax=ax[1, 1], label='kde estimate')\n",
    "    ax[1, 1].plot(x, norm.pdf(x), label='normal distribution')\n",
    "    ax[1, 1].legend()\n",
    "    ax[1, 1].set_title('Distribution of Residuals')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_plot(model_test_201.resid.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic selection of ARIMA model\n",
    "\n",
    "We can use automatic methods to select the parameters for the ARIMA model. One package that is available is `pmdarima`, you can install if it's the first time you are using it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pmdarima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "auto_arima = pm.auto_arima(X_train, stepwise=False, seasonal=False)\n",
    "auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_test_auto = auto_arima.predict(n_periods=len(X_test))\n",
    "data['forecast_auto'] = [None]*len(X_train) + list(forecast_test_auto)\n",
    "\n",
    "data.loc['2023-01':].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the forecast for the automatic ARIMA are similar with order = (1,1,2) to the one that we used with order=(1,1,15). A simpler model is always preferred.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish different ways of forecasting.\n",
    "\n",
    "- In-sample forecasts:\n",
    " - We predict one-step ahead using the true values up to that point (non-dynamic forecasting).\n",
    " - We use the first few values in the time series to predict the next ones, and the ones further in the future using the predicted values as input (dynamic forecasting).\n",
    "- Out-of-sample forecasts:\n",
    " - We predict further into the future using predicted values as input.\n",
    " - If we predict for a long time into the future, our forecast will be (very close to) the mean.\n",
    " - It is important to indicate confidence intervals for our forecast. We can never be sure about the future, but we can be reasonably sure that future values will stay within certain bounds.\n",
    " - The width of the confidence interval becomes constant. This is due to stationarity. For a non-stationary time series, the confidence interval would become wider and wider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "\n",
    "# Start predicting from which time period\n",
    "init_1 = 2\n",
    "\n",
    "# Stop predicting 50 time units into the future (50 months)\n",
    "end_1 = len(urate)+50\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "urate.plot()\n",
    "plot_predict(model_1_1_15,init_1,end_1,dynamic=False,plot_insample=True,ax=ax)\n",
    "ax.set_title('Non dynamic in-sample predictions and out-of-sample forecasts',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `dynamic=True` uses each predicted value to predict the next, instead of using the true values, so there will be a difference depending on where the prediction starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "\n",
    "# Start predicting from which time period\n",
    "#init_1 = 2\n",
    "init_1=len(urate)-30\n",
    "# Stop predicting 50 time units into the future (50 months)\n",
    "end_1 = len(urate)+50\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "urate.plot()\n",
    "plot_predict(model_1_1_15,init_1,end_1,dynamic=True,plot_insample=True,ax=ax)\n",
    "ax.set_title('Dynamic In-sample predictions and out-of-sample forecasts',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our usual scores to compare true and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(X_test, forecast_test_auto)\n",
    "mape = mean_absolute_percentage_error(X_test, forecast_test_auto)\n",
    "mse = mean_squared_error(X_test, forecast_test_auto)\n",
    "rmse = np.sqrt(mean_squared_error(X_test, forecast_test_auto))\n",
    "\n",
    "print(f'mae - auto: {mae}')\n",
    "print(f'mape - auto: {mape}')\n",
    "print(f'rmse - auto: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(X_test, forecast_1_1_15 )\n",
    "mape = mean_absolute_percentage_error(X_test,forecast_1_1_15 )\n",
    "mse = mean_squared_error(X_test, forecast_1_1_15)\n",
    "rmse = np.sqrt(mean_squared_error(X_test, forecast_1_1_15 ))\n",
    "\n",
    "\n",
    "print(f'mae - manual: {mae}')\n",
    "print(f'mape - manual: {mape}')\n",
    "print(f'mse - manual: {mse}')\n",
    "print(f'rmse - manual: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(X_test, forecast_test_201 )\n",
    "mape = mean_absolute_percentage_error(X_test,forecast_test_201 )\n",
    "mse = mean_squared_error(X_test, forecast_test_201)\n",
    "rmse = np.sqrt(mean_squared_error(X_test, forecast_test_201 ))\n",
    "\n",
    "\n",
    "print(f'mae - manual: {mae}')\n",
    "print(f'mape - manual: {mape}')\n",
    "print(f'mse - manual: {mse}')\n",
    "print(f'rmse - manual: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of time series modeling\n",
    "\n",
    "- Visualize the time series\n",
    "- Make the time series stationary\n",
    " - Is there a clear trend in the data?\n",
    " - Are there periodic patterns / seasonal effects?\n",
    "- Plot ACF/PACF to seek optimal parameters\n",
    "- Build the ARIMA model\n",
    "- Predict the future\n",
    "    - Obtain in-sample and out-of-sample forecasts\n",
    "    - Evaluate model scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Limitations\n",
    "\n",
    "- We made assumptions about stationarity\n",
    "- Trends can be removed by transformation and/or differencing\n",
    "- Long term patterns in the correlations can be taken into account by Seasonal ARIMA models \n",
    "- Time dependent variances of the error term can be taken into account by GARCH models\n",
    "- There are many more specialized models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [Blackarbs - Time series analysis in python - linear models to garch](http://www.blackarbs.com/blog/time-series-analysis-in-python-linear-models-to-garch/11/1/2016)\n",
    "- [Quantstart - time series analysis](https://www.quantstart.com/articles#time-series-analysis)\n",
    "- [Digital Ocean - A guide to time series forecasting](https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-arima-in-python-3)\n",
    "- [Harvard lectures](http://iacs-courses.seas.harvard.edu/courses/am207/blog/lecture-17.html)\n",
    "- [Statsmodels ARMA Example](http://www.statsmodels.org/devel/examples/notebooks/generated/tsa_arma_0.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "337px",
    "left": "0px",
    "right": "615.295px",
    "top": "62px",
    "width": "165px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
